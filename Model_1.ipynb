{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSZHabibie/AccountVerify/blob/master/Model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# City Based Weather Analysis"
      ],
      "metadata": {
        "id": "3hWsdMSWy203"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "import requests\n",
        "# Enter the api key of openweathermap here\n",
        "api_key = \"81c713c1b0fea513c62681c97920daa9\"\n",
        "# Base url for the open map api\n",
        "root_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
        "# Input the City name for which we need the weather data\n",
        "city_name = input(\"Please Enter The City Name : \")\n",
        "# Building the final url for the API call\n",
        "url = f\"{root_url}appid={api_key}&q={city_name}\"\n",
        "# sending a get request at the url\n",
        "r = requests.get(url)\n",
        "# storing the returned json data into a variable\n",
        "data = r.json()\n",
        "# Checking If there is no error and the status code is 200\n",
        "if data['cod'] == 200:\n",
        "    # getting the temperature from the json data\n",
        "    temp = data['main']['temp'] - 273.15\n",
        "    # getting the pressure from the json data\n",
        "    pressure = data['main']['pressure']\n",
        "    # getting the humidity from the json data\n",
        "    humidity = data['main']['humidity']\n",
        "    # getting the description from the json data\n",
        "    descr = data['weather'][0]['description']\n",
        "    # getting the wind speed from the json data\n",
        "    wind = data['wind']['speed']\n",
        "    # Displaying all the data\n",
        "    print(f\"City Name : {city_name}\")\n",
        "    print(f\"The Weather Condition is {descr}\")\n",
        "    print(f\"The temperature is {temp :.2f} Celsius\")\n",
        "    print(f\"The pressure is {pressure}hPa\")\n",
        "    print(f\"The humidity is {humidity}%\")\n",
        "    print(f\"The speed of wind is {wind}m/s\")\n",
        "    print(url)\n",
        "else:\n",
        "    # If any error occured then print this\n",
        "    print(\"Something Went Wrong\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fam5io_64MMA",
        "outputId": "2bb28f98-7d75-412a-8a9b-a2fe846698b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter The City Name : Jakarta\n",
            "City Name : Jakarta\n",
            "The Weather Condition is heavy intensity rain\n",
            "The temperature is 22.96 Celsius\n",
            "The pressure is 1010hPa\n",
            "The humidity is 83%\n",
            "The speed of wind is 1.51m/s\n",
            "http://api.openweathermap.org/data/2.5/weather?appid=81c713c1b0fea513c62681c97920daa9&q=Jakarta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improved City Based Weather Analysis but just avg Temp within month"
      ],
      "metadata": {
        "id": "AD9D0Qouq5RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "today = datetime.today()\n",
        "\n",
        "api_key = \"81c713c1b0fea513c62681c97920daa9\"\n",
        "\n",
        "root_url = \"https://history.openweathermap.org/data/2.5/aggregated/month?\"\n",
        "\n",
        "city_name = input(\"Please Enter The City Name : \")\n",
        "\n",
        "url = f\"{root_url}month={today.month}&q={city_name},ID&appid={api_key}\"\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "data = r.json()\n",
        "# Checking If there is no error and the status code is 200\n",
        "if data['cod'] == 200:\n",
        "    # getting the temperature from the json data\n",
        "    temp = data['result']['temp']['mean'] - 273.15\n",
        "    # getting the humidity from the json data\n",
        "    humidity = data['result']['humidity']['mean']\n",
        "    # getting the month from the json data\n",
        "    month = data['result']['month']\n",
        "    print(f\"City Name : {city_name}\")\n",
        "    print(f\"The avg temperature in month {month} is {temp :.2f} Celsius\")\n",
        "    print(f\"The avg humidity in month {month} is {humidity :.2f} %\")\n",
        "    print(url)\n",
        "else:\n",
        "    message = data['message']\n",
        "    print(\"Something Went Wrong,\", message)"
      ],
      "metadata": {
        "id": "Xv_g8NqYq2t8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fec13c-dc5e-4976-e870-9dbfe7f150d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter The City Name : Jakarta\n",
            "City Name : Jakarta\n",
            "The avg temperature in month 5 is 28.63 Celsius\n",
            "The avg humidity in month 5 is 77.34 %\n",
            "https://history.openweathermap.org/data/2.5/aggregated/month?month=5&q=Jakarta,ID&appid=81c713c1b0fea513c62681c97920daa9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error handling with try except for location that has no weather history data"
      ],
      "metadata": {
        "id": "UFzlOgwNcJ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "today = datetime.today()\n",
        "\n",
        "api_key = \"81c713c1b0fea513c62681c97920daa9\"\n",
        "city_name = input(\"Please Enter The City Name : \")\n",
        "\n",
        "###########################################################################\n",
        "# Bisa dijadikan Method #\n",
        "root_url = \"https://history.openweathermap.org/data/2.5/aggregated/month?\"\n",
        "url = f\"{root_url}month={today.month}&q={city_name},ID&appid={api_key}\"\n",
        "r = requests.get(url)\n",
        "data = r.json()\n",
        "\n",
        "root_url2 = \"https://api.openweathermap.org/data/2.5/weather?\"\n",
        "url2 = f\"{root_url2}q={city_name}&appid={api_key}\"\n",
        "r2 = requests.get(url2)\n",
        "data2 = r2.json()\n",
        "############################################################################\n",
        "\n",
        "# Checking If there is no error and the status code is 200\n",
        "try:\n",
        "  if data['cod'] == 200:\n",
        "      # getting the temperature from the json data\n",
        "      temp = data['result']['temp']['mean'] - 273.15\n",
        "      # getting the humidity from the json data\n",
        "      humidity = data['result']['humidity']['mean']\n",
        "      # getting the month from the json data\n",
        "      month = data['result']['month']\n",
        "      print(f\"City Name : {city_name}\")\n",
        "      print(f\"The avg temperature in month {month} is {temp :.2f} Celsius\")\n",
        "      print(f\"The avg humidity in month {month} is {humidity :.2f} %\")\n",
        "      print(url)\n",
        "  else:\n",
        "      message = data['message']\n",
        "      print(\"Something Went Wrong,\", message)\n",
        "except:\n",
        "  if data['code'] == 404000:\n",
        "    message = data['message']\n",
        "    print(f\"Error, {message}. Switching to current weather....\")\n",
        "    # getting the temperature from the json data\n",
        "    temp = data2['main']['temp'] - 273.15\n",
        "    # getting the humidity from the json data\n",
        "    humidity = data2['main']['humidity']\n",
        "    print(f\"City Name : {city_name}\")\n",
        "    print(f\"The current temperature is {temp :.2f} Celsius\")\n",
        "    print(f\"The current humidity is {humidity :.2f} %\")\n",
        "    print(url2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4jWOqCidLZM",
        "outputId": "eed1639c-b75b-4edd-9c6b-2f290088997c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter The City Name : banda aceh\n",
            "City Name : banda aceh\n",
            "The avg temperature in month 5 is 27.57 Celsius\n",
            "The avg humidity in month 5 is 82.02 %\n",
            "https://history.openweathermap.org/data/2.5/aggregated/month?month=5&q=banda aceh,ID&appid=81c713c1b0fea513c62681c97920daa9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy Dataset"
      ],
      "metadata": {
        "id": "EUa485-lTZQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "data1 =pd.DataFrame({\"Temperature\" : np.random.uniform(20, 33, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 61, 500).round(2),\n",
        "                     \"Label\"  : \"Bayam Hijau\"})\n",
        "data2 =pd.DataFrame({\"Temperature\" : np.random.uniform(20,28, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(60, 81, 500).round(2),\n",
        "                     \"Label\"  : \"Tomat\"})\n",
        "data3 =pd.DataFrame({\"Temperature\" : np.random.uniform(25,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 81 , 500).round(2),\n",
        "                     \"Label\"  : \"Kangkung\"})\n",
        "data4 =pd.DataFrame({\"Temperature\" : np.random.uniform(22,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(80, 91, 500).round(2),\n",
        "                     \"Label\"  : \"Terung\"})\n",
        "data5 =pd.DataFrame({\"Temperature\" : np.random.uniform(18,20, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(80, 91, 500).round(2),\n",
        "                     \"Label\"  : \"Kubis\"})\n",
        "data6 =pd.DataFrame({\"Temperature\" : np.random.uniform(21,32, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(2,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(30, 51, 500).round(2),\n",
        "                     \"Label\"  : \"Lidah Mertua\"})\n",
        "data7 =pd.DataFrame({\"Temperature\" : np.random.uniform(23,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.4, 0.5, 0.1], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(2,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 61, 500).round(2),\n",
        "                     \"Label\"  : \"Sri Rezeki\"})\n",
        "data8 =pd.DataFrame({\"Temperature\" : np.random.uniform(20,33, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(35, 46, 500).round(2),\n",
        "                     \"Label\"  : \"Lidah Buaya\"})\n",
        "data9 =pd.DataFrame({\"Temperature\" : np.random.uniform(18,31, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 71, 500).round(2),\n",
        "                     \"Label\"  : \"Kuping Gajah\"})\n",
        "data10 =pd.DataFrame({\"Temperature\" : np.random.uniform(16,32, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(80, 96, 500).round(2),\n",
        "                     \"Label\"  : \"Lavender\"})\n",
        "data11 =pd.DataFrame({\"Temperature\" : np.random.uniform(16,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.3, 0.3, 0.4], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 61, 500).round(2),\n",
        "                     \"Label\"  : \"Mawar\"})\n",
        "data12 =pd.DataFrame({\"Temperature\" : np.random.uniform(24,36, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.4, 0.2, 0.4], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 81, 500).round(2),\n",
        "                     \"Label\"  : \"Melati\"})"
      ],
      "metadata": {
        "id": "kKUc71aXWaw5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data1.append(data2, ignore_index=True).append(data3, ignore_index=True).append(data4, ignore_index=True).append(data5, ignore_index=True)\\\n",
        "          .append(data6, ignore_index=True).append(data7, ignore_index=True).append(data8, ignore_index=True).append(data9, ignore_index=True)\\\n",
        "          .append(data10, ignore_index=True).append(data11, ignore_index=True).append(data12, ignore_index=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5PVSyF0qpaCY",
        "outputId": "9b82ddf7-9edb-4279-fe8e-c75cb30f777d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Temperature  Soil  Light  Humid        Label\n",
              "0           27.13     2      1  56.52  Bayam Hijau\n",
              "1           29.30     2      1  50.11  Bayam Hijau\n",
              "2           27.84     2      1  55.23  Bayam Hijau\n",
              "3           27.08     2      1  57.80  Bayam Hijau\n",
              "4           25.51     2      1  50.48  Bayam Hijau\n",
              "...           ...   ...    ...    ...          ...\n",
              "5995        28.82     3      1  63.40       Melati\n",
              "5996        34.49     2      1  79.80       Melati\n",
              "5997        30.43     3      1  60.23       Melati\n",
              "5998        28.25     1      1  50.85       Melati\n",
              "5999        35.23     2      1  74.19       Melati\n",
              "\n",
              "[6000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd09f548-022a-4cb0-b6f6-f026c2fdf94a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Soil</th>\n",
              "      <th>Light</th>\n",
              "      <th>Humid</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>56.52</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29.30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50.11</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27.84</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>55.23</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.08</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57.80</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.51</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50.48</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>28.82</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>63.40</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>34.49</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>79.80</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>30.43</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>60.23</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>28.25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.85</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>35.23</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>74.19</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd09f548-022a-4cb0-b6f6-f026c2fdf94a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd09f548-022a-4cb0-b6f6-f026c2fdf94a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd09f548-022a-4cb0-b6f6-f026c2fdf94a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation | TensorFlow Raw"
      ],
      "metadata": {
        "id": "c9yVSA4jTP32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "AnFnIzT1kzvY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    # Check accuracy\n",
        "    if(logs.get('accuracy') > 0.8):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\naccuracy is more than 0.8 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "rBTiGNFBFG2z"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,4].values"
      ],
      "metadata": {
        "id": "chYQosI7R4J9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0:5])\n",
        "print(y[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R6jCOWpR-vm",
        "outputId": "77e629b0-74d8-485e-a800-761156eb0907"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27.13  2.    1.   56.52]\n",
            " [29.3   2.    1.   50.11]\n",
            " [27.84  2.    1.   55.23]\n",
            " [27.08  2.    1.   57.8 ]\n",
            " [25.51  2.    1.   50.48]]\n",
            "['Bayam Hijau' 'Bayam Hijau' 'Bayam Hijau' 'Bayam Hijau' 'Bayam Hijau']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "4Xf53TJ3SLK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129a6eba-a1e9-4256-ad02-4e667bbff50b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000, 4)\n",
            "(6000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder =  LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Lj2Who3oSMu-"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y1)"
      ],
      "metadata": {
        "id": "xf_vs3-QSPIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ce68fa-7f88-4377-878d-31b62873a8e9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 8 8 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(y1).values\n",
        "print(Y[0:5])"
      ],
      "metadata": {
        "id": "JSaprB5lSRC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642aeac3-cd79-499b-9045-c23b2b6201ed"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# set aside 20% of train and test data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
        "    test_size=0.2, shuffle = True, random_state = 8)\n",
        "\n",
        "# Use the same function above for the validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
        "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2"
      ],
      "metadata": {
        "id": "sNxZyS-fSTKO"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0:5])"
      ],
      "metadata": {
        "id": "rDqZLG76SVtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e4b7e2-eaa7-4dec-fa6d-02d882ff2108"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25.34  2.    2.   64.7 ]\n",
            " [31.95  2.    1.   55.57]\n",
            " [23.    1.    1.   81.54]\n",
            " [25.38  3.    1.   52.85]\n",
            " [22.39  2.    1.   52.67]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0:5])"
      ],
      "metadata": {
        "id": "eKJTsFXxSZ_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e60fd4d-32a2-49bd-af7e-17cd5f858154"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[0:5])"
      ],
      "metadata": {
        "id": "WO6FiKmKSbsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a656a3-4b13-4a07-9c33-7f3577d1bc85"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18.19  2.    1.   80.47]\n",
            " [19.96  3.    1.   80.09]\n",
            " [23.51  1.    2.   36.69]\n",
            " [25.73  2.    1.   60.55]\n",
            " [27.46  1.    1.   80.93]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[0:5])"
      ],
      "metadata": {
        "id": "OwMTbCGpSdYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f680c068-cfe1-45cc-a679-8447035cb75f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(18, activation='relu'),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "  ])\n",
        "model"
      ],
      "metadata": {
        "id": "D8LgKJYjSe46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2596ba-6b9a-49b9-c0cd-baf44f7873e4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f7cf69932d0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x1oV8kUzSg8C"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=50, \n",
        "                    epochs=500, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "qo06yjzISipL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a2099a-6603-499a-efeb-0daa632da99c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "72/72 [==============================] - 1s 5ms/step - loss: 4.2840 - accuracy: 0.1339 - val_loss: 2.4261 - val_accuracy: 0.1917\n",
            "Epoch 2/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2.3598 - accuracy: 0.1700 - val_loss: 2.2794 - val_accuracy: 0.2133\n",
            "Epoch 3/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2.2535 - accuracy: 0.1750 - val_loss: 2.1784 - val_accuracy: 0.2067\n",
            "Epoch 4/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 2.1565 - accuracy: 0.1892 - val_loss: 2.0900 - val_accuracy: 0.2192\n",
            "Epoch 5/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2.0478 - accuracy: 0.2039 - val_loss: 1.9675 - val_accuracy: 0.2475\n",
            "Epoch 6/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.9356 - accuracy: 0.2558 - val_loss: 1.8768 - val_accuracy: 0.2800\n",
            "Epoch 7/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.8354 - accuracy: 0.2953 - val_loss: 1.7930 - val_accuracy: 0.3342\n",
            "Epoch 8/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.7619 - accuracy: 0.3242 - val_loss: 1.7013 - val_accuracy: 0.3583\n",
            "Epoch 9/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.7216 - accuracy: 0.3194 - val_loss: 1.6914 - val_accuracy: 0.3175\n",
            "Epoch 10/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.6736 - accuracy: 0.3492 - val_loss: 1.6284 - val_accuracy: 0.3550\n",
            "Epoch 11/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.6348 - accuracy: 0.3508 - val_loss: 1.6060 - val_accuracy: 0.3808\n",
            "Epoch 12/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.6088 - accuracy: 0.3681 - val_loss: 1.5535 - val_accuracy: 0.3908\n",
            "Epoch 13/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.5801 - accuracy: 0.3919 - val_loss: 1.5441 - val_accuracy: 0.4058\n",
            "Epoch 14/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.5538 - accuracy: 0.3869 - val_loss: 1.5143 - val_accuracy: 0.4133\n",
            "Epoch 15/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.5363 - accuracy: 0.3811 - val_loss: 1.5132 - val_accuracy: 0.4150\n",
            "Epoch 16/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.5009 - accuracy: 0.3981 - val_loss: 1.4411 - val_accuracy: 0.4300\n",
            "Epoch 17/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.4796 - accuracy: 0.4072 - val_loss: 1.4334 - val_accuracy: 0.4417\n",
            "Epoch 18/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.4710 - accuracy: 0.4111 - val_loss: 1.3996 - val_accuracy: 0.4625\n",
            "Epoch 19/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.4317 - accuracy: 0.4222 - val_loss: 1.3651 - val_accuracy: 0.4517\n",
            "Epoch 20/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.4174 - accuracy: 0.4286 - val_loss: 1.3581 - val_accuracy: 0.4692\n",
            "Epoch 21/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.3934 - accuracy: 0.4292 - val_loss: 1.3597 - val_accuracy: 0.4683\n",
            "Epoch 22/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.3800 - accuracy: 0.4289 - val_loss: 1.3358 - val_accuracy: 0.4883\n",
            "Epoch 23/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.3528 - accuracy: 0.4464 - val_loss: 1.3232 - val_accuracy: 0.4533\n",
            "Epoch 24/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.3367 - accuracy: 0.4444 - val_loss: 1.2877 - val_accuracy: 0.4808\n",
            "Epoch 25/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.3294 - accuracy: 0.4492 - val_loss: 1.2865 - val_accuracy: 0.4875\n",
            "Epoch 26/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.3090 - accuracy: 0.4547 - val_loss: 1.2569 - val_accuracy: 0.4875\n",
            "Epoch 27/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.2946 - accuracy: 0.4592 - val_loss: 1.2499 - val_accuracy: 0.4550\n",
            "Epoch 28/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.2943 - accuracy: 0.4614 - val_loss: 1.2327 - val_accuracy: 0.4958\n",
            "Epoch 29/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.2706 - accuracy: 0.4700 - val_loss: 1.2306 - val_accuracy: 0.4925\n",
            "Epoch 30/500\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.2590 - accuracy: 0.4714 - val_loss: 1.2295 - val_accuracy: 0.5008\n",
            "Epoch 31/500\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1.2559 - accuracy: 0.4761 - val_loss: 1.2547 - val_accuracy: 0.4708\n",
            "Epoch 32/500\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 1.2569 - accuracy: 0.4808 - val_loss: 1.2100 - val_accuracy: 0.4850\n",
            "Epoch 33/500\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 1.2394 - accuracy: 0.4842 - val_loss: 1.2027 - val_accuracy: 0.4992\n",
            "Epoch 34/500\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 1.2334 - accuracy: 0.4833 - val_loss: 1.1945 - val_accuracy: 0.5208\n",
            "Epoch 35/500\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1.2181 - accuracy: 0.4894 - val_loss: 1.1946 - val_accuracy: 0.5175\n",
            "Epoch 36/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.2256 - accuracy: 0.4967 - val_loss: 1.1893 - val_accuracy: 0.4858\n",
            "Epoch 37/500\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 1.2161 - accuracy: 0.4936 - val_loss: 1.1671 - val_accuracy: 0.4975\n",
            "Epoch 38/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1975 - accuracy: 0.5106 - val_loss: 1.1596 - val_accuracy: 0.5183\n",
            "Epoch 39/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1884 - accuracy: 0.4986 - val_loss: 1.1413 - val_accuracy: 0.5217\n",
            "Epoch 40/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1851 - accuracy: 0.4992 - val_loss: 1.1410 - val_accuracy: 0.5400\n",
            "Epoch 41/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1855 - accuracy: 0.4958 - val_loss: 1.1621 - val_accuracy: 0.5225\n",
            "Epoch 42/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1843 - accuracy: 0.5042 - val_loss: 1.1263 - val_accuracy: 0.5283\n",
            "Epoch 43/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1787 - accuracy: 0.4972 - val_loss: 1.1217 - val_accuracy: 0.5125\n",
            "Epoch 44/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1595 - accuracy: 0.5181 - val_loss: 1.1335 - val_accuracy: 0.5350\n",
            "Epoch 45/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1599 - accuracy: 0.5189 - val_loss: 1.1381 - val_accuracy: 0.5075\n",
            "Epoch 46/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1480 - accuracy: 0.5081 - val_loss: 1.1320 - val_accuracy: 0.5350\n",
            "Epoch 47/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1446 - accuracy: 0.5147 - val_loss: 1.1467 - val_accuracy: 0.5308\n",
            "Epoch 48/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1438 - accuracy: 0.5167 - val_loss: 1.1487 - val_accuracy: 0.5067\n",
            "Epoch 49/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1365 - accuracy: 0.5147 - val_loss: 1.1008 - val_accuracy: 0.5267\n",
            "Epoch 50/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1236 - accuracy: 0.5211 - val_loss: 1.0796 - val_accuracy: 0.5542\n",
            "Epoch 51/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1305 - accuracy: 0.5194 - val_loss: 1.0806 - val_accuracy: 0.5492\n",
            "Epoch 52/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1343 - accuracy: 0.5194 - val_loss: 1.0817 - val_accuracy: 0.5433\n",
            "Epoch 53/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1089 - accuracy: 0.5353 - val_loss: 1.0789 - val_accuracy: 0.5617\n",
            "Epoch 54/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1321 - accuracy: 0.5153 - val_loss: 1.1271 - val_accuracy: 0.5325\n",
            "Epoch 55/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1094 - accuracy: 0.5314 - val_loss: 1.0618 - val_accuracy: 0.5783\n",
            "Epoch 56/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1068 - accuracy: 0.5344 - val_loss: 1.0905 - val_accuracy: 0.5367\n",
            "Epoch 57/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.1078 - accuracy: 0.5244 - val_loss: 1.1000 - val_accuracy: 0.5392\n",
            "Epoch 58/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.0878 - accuracy: 0.5381 - val_loss: 1.0713 - val_accuracy: 0.5550\n",
            "Epoch 59/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.0832 - accuracy: 0.5422 - val_loss: 1.0489 - val_accuracy: 0.5533\n",
            "Epoch 60/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0751 - accuracy: 0.5458 - val_loss: 1.0466 - val_accuracy: 0.5658\n",
            "Epoch 61/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.0770 - accuracy: 0.5461 - val_loss: 1.0647 - val_accuracy: 0.5600\n",
            "Epoch 62/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.0651 - accuracy: 0.5522 - val_loss: 1.0630 - val_accuracy: 0.5450\n",
            "Epoch 63/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0571 - accuracy: 0.5528 - val_loss: 1.0661 - val_accuracy: 0.5483\n",
            "Epoch 64/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.5483 - val_loss: 1.0295 - val_accuracy: 0.5767\n",
            "Epoch 65/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0589 - accuracy: 0.5467 - val_loss: 1.0237 - val_accuracy: 0.5700\n",
            "Epoch 66/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0448 - accuracy: 0.5622 - val_loss: 1.0391 - val_accuracy: 0.5725\n",
            "Epoch 67/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0418 - accuracy: 0.5669 - val_loss: 1.0042 - val_accuracy: 0.5833\n",
            "Epoch 68/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.0328 - accuracy: 0.5697 - val_loss: 1.0220 - val_accuracy: 0.5783\n",
            "Epoch 69/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0377 - accuracy: 0.5583 - val_loss: 0.9907 - val_accuracy: 0.5950\n",
            "Epoch 70/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0295 - accuracy: 0.5589 - val_loss: 0.9886 - val_accuracy: 0.5983\n",
            "Epoch 71/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5769 - val_loss: 0.9961 - val_accuracy: 0.5983\n",
            "Epoch 72/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.5811 - val_loss: 0.9908 - val_accuracy: 0.5850\n",
            "Epoch 73/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0071 - accuracy: 0.5797 - val_loss: 1.0027 - val_accuracy: 0.5967\n",
            "Epoch 74/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.5853 - val_loss: 1.0095 - val_accuracy: 0.5808\n",
            "Epoch 75/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.0124 - accuracy: 0.5778 - val_loss: 0.9806 - val_accuracy: 0.6117\n",
            "Epoch 76/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9969 - accuracy: 0.5881 - val_loss: 1.0033 - val_accuracy: 0.5725\n",
            "Epoch 77/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9962 - accuracy: 0.5878 - val_loss: 0.9612 - val_accuracy: 0.6083\n",
            "Epoch 78/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9792 - accuracy: 0.5958 - val_loss: 0.9768 - val_accuracy: 0.5917\n",
            "Epoch 79/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9808 - accuracy: 0.5953 - val_loss: 0.9631 - val_accuracy: 0.6125\n",
            "Epoch 80/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9761 - accuracy: 0.5956 - val_loss: 0.9535 - val_accuracy: 0.6058\n",
            "Epoch 81/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9781 - accuracy: 0.5992 - val_loss: 0.9846 - val_accuracy: 0.6075\n",
            "Epoch 82/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9636 - accuracy: 0.6006 - val_loss: 0.9467 - val_accuracy: 0.6208\n",
            "Epoch 83/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9723 - accuracy: 0.5922 - val_loss: 0.9421 - val_accuracy: 0.6167\n",
            "Epoch 84/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9552 - accuracy: 0.6039 - val_loss: 0.9264 - val_accuracy: 0.6192\n",
            "Epoch 85/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9459 - accuracy: 0.6064 - val_loss: 0.9892 - val_accuracy: 0.5958\n",
            "Epoch 86/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9490 - accuracy: 0.6061 - val_loss: 0.9103 - val_accuracy: 0.6300\n",
            "Epoch 87/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9420 - accuracy: 0.6144 - val_loss: 1.0154 - val_accuracy: 0.5475\n",
            "Epoch 88/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9575 - accuracy: 0.6008 - val_loss: 0.9242 - val_accuracy: 0.6233\n",
            "Epoch 89/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9504 - accuracy: 0.6006 - val_loss: 0.9955 - val_accuracy: 0.5992\n",
            "Epoch 90/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.6028 - val_loss: 1.0028 - val_accuracy: 0.5883\n",
            "Epoch 91/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9427 - accuracy: 0.6014 - val_loss: 0.9847 - val_accuracy: 0.5958\n",
            "Epoch 92/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9400 - accuracy: 0.6136 - val_loss: 0.9156 - val_accuracy: 0.6308\n",
            "Epoch 93/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9355 - accuracy: 0.6072 - val_loss: 0.9103 - val_accuracy: 0.6325\n",
            "Epoch 94/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9237 - accuracy: 0.6119 - val_loss: 1.0147 - val_accuracy: 0.5808\n",
            "Epoch 95/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9386 - accuracy: 0.5967 - val_loss: 0.9168 - val_accuracy: 0.6167\n",
            "Epoch 96/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9452 - accuracy: 0.6053 - val_loss: 0.9040 - val_accuracy: 0.6267\n",
            "Epoch 97/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.6139 - val_loss: 0.9382 - val_accuracy: 0.6092\n",
            "Epoch 98/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9148 - accuracy: 0.6242 - val_loss: 0.8887 - val_accuracy: 0.6308\n",
            "Epoch 99/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9110 - accuracy: 0.6189 - val_loss: 0.9055 - val_accuracy: 0.6200\n",
            "Epoch 100/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9125 - accuracy: 0.6208 - val_loss: 0.8899 - val_accuracy: 0.6375\n",
            "Epoch 101/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9053 - accuracy: 0.6222 - val_loss: 0.9166 - val_accuracy: 0.6033\n",
            "Epoch 102/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9021 - accuracy: 0.6147 - val_loss: 0.9047 - val_accuracy: 0.6250\n",
            "Epoch 103/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9109 - accuracy: 0.6175 - val_loss: 0.9336 - val_accuracy: 0.6083\n",
            "Epoch 104/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9191 - accuracy: 0.6081 - val_loss: 0.9025 - val_accuracy: 0.6200\n",
            "Epoch 105/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8890 - accuracy: 0.6278 - val_loss: 0.9020 - val_accuracy: 0.6350\n",
            "Epoch 106/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8937 - accuracy: 0.6228 - val_loss: 0.9149 - val_accuracy: 0.6200\n",
            "Epoch 107/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9057 - accuracy: 0.6206 - val_loss: 0.8792 - val_accuracy: 0.6425\n",
            "Epoch 108/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8926 - accuracy: 0.6228 - val_loss: 0.8749 - val_accuracy: 0.6550\n",
            "Epoch 109/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8944 - accuracy: 0.6219 - val_loss: 0.8688 - val_accuracy: 0.6467\n",
            "Epoch 110/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8893 - accuracy: 0.6208 - val_loss: 0.8806 - val_accuracy: 0.6283\n",
            "Epoch 111/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8825 - accuracy: 0.6289 - val_loss: 0.8609 - val_accuracy: 0.6558\n",
            "Epoch 112/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8771 - accuracy: 0.6311 - val_loss: 0.9277 - val_accuracy: 0.6183\n",
            "Epoch 113/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8885 - accuracy: 0.6197 - val_loss: 0.9767 - val_accuracy: 0.5867\n",
            "Epoch 114/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9134 - accuracy: 0.6017 - val_loss: 0.9773 - val_accuracy: 0.5925\n",
            "Epoch 115/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9058 - accuracy: 0.6142 - val_loss: 0.8913 - val_accuracy: 0.6133\n",
            "Epoch 116/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8915 - accuracy: 0.6139 - val_loss: 0.8798 - val_accuracy: 0.6200\n",
            "Epoch 117/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8760 - accuracy: 0.6306 - val_loss: 0.8801 - val_accuracy: 0.6250\n",
            "Epoch 118/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8783 - accuracy: 0.6258 - val_loss: 0.9053 - val_accuracy: 0.6183\n",
            "Epoch 119/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8724 - accuracy: 0.6256 - val_loss: 0.8896 - val_accuracy: 0.6267\n",
            "Epoch 120/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.6169 - val_loss: 0.8783 - val_accuracy: 0.6275\n",
            "Epoch 121/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8915 - accuracy: 0.6164 - val_loss: 0.9032 - val_accuracy: 0.6308\n",
            "Epoch 122/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8856 - accuracy: 0.6169 - val_loss: 0.8688 - val_accuracy: 0.6325\n",
            "Epoch 123/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8819 - accuracy: 0.6258 - val_loss: 0.8475 - val_accuracy: 0.6592\n",
            "Epoch 124/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9077 - accuracy: 0.6239 - val_loss: 0.8837 - val_accuracy: 0.6150\n",
            "Epoch 125/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8793 - accuracy: 0.6153 - val_loss: 0.8659 - val_accuracy: 0.6350\n",
            "Epoch 126/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8964 - accuracy: 0.6217 - val_loss: 0.9056 - val_accuracy: 0.6208\n",
            "Epoch 127/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8848 - accuracy: 0.6217 - val_loss: 0.8766 - val_accuracy: 0.6100\n",
            "Epoch 128/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8645 - accuracy: 0.6342 - val_loss: 0.8416 - val_accuracy: 0.6425\n",
            "Epoch 129/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8720 - accuracy: 0.6208 - val_loss: 0.8556 - val_accuracy: 0.6533\n",
            "Epoch 130/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8685 - accuracy: 0.6236 - val_loss: 0.8954 - val_accuracy: 0.6258\n",
            "Epoch 131/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8675 - accuracy: 0.6358 - val_loss: 0.8490 - val_accuracy: 0.6408\n",
            "Epoch 132/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8732 - accuracy: 0.6258 - val_loss: 0.8474 - val_accuracy: 0.6450\n",
            "Epoch 133/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8621 - accuracy: 0.6353 - val_loss: 0.8711 - val_accuracy: 0.6467\n",
            "Epoch 134/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8876 - accuracy: 0.6239 - val_loss: 0.8531 - val_accuracy: 0.6408\n",
            "Epoch 135/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8578 - accuracy: 0.6256 - val_loss: 0.8658 - val_accuracy: 0.6250\n",
            "Epoch 136/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8547 - accuracy: 0.6339 - val_loss: 0.8480 - val_accuracy: 0.6392\n",
            "Epoch 137/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8728 - accuracy: 0.6214 - val_loss: 0.9752 - val_accuracy: 0.6008\n",
            "Epoch 138/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8634 - accuracy: 0.6294 - val_loss: 0.8415 - val_accuracy: 0.6467\n",
            "Epoch 139/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8616 - accuracy: 0.6281 - val_loss: 0.8438 - val_accuracy: 0.6500\n",
            "Epoch 140/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8611 - accuracy: 0.6306 - val_loss: 0.8479 - val_accuracy: 0.6475\n",
            "Epoch 141/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.6333 - val_loss: 0.8393 - val_accuracy: 0.6417\n",
            "Epoch 142/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8577 - accuracy: 0.6286 - val_loss: 0.9405 - val_accuracy: 0.5983\n",
            "Epoch 143/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8504 - accuracy: 0.6314 - val_loss: 0.8637 - val_accuracy: 0.6367\n",
            "Epoch 144/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8450 - accuracy: 0.6319 - val_loss: 0.8516 - val_accuracy: 0.6367\n",
            "Epoch 145/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8488 - accuracy: 0.6322 - val_loss: 0.8557 - val_accuracy: 0.6350\n",
            "Epoch 146/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8438 - accuracy: 0.6381 - val_loss: 0.8633 - val_accuracy: 0.6233\n",
            "Epoch 147/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8476 - accuracy: 0.6386 - val_loss: 0.8446 - val_accuracy: 0.6567\n",
            "Epoch 148/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8581 - accuracy: 0.6306 - val_loss: 0.8777 - val_accuracy: 0.6283\n",
            "Epoch 149/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8469 - accuracy: 0.6361 - val_loss: 0.8377 - val_accuracy: 0.6367\n",
            "Epoch 150/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8516 - accuracy: 0.6286 - val_loss: 0.9167 - val_accuracy: 0.6175\n",
            "Epoch 151/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8458 - accuracy: 0.6269 - val_loss: 0.8999 - val_accuracy: 0.6267\n",
            "Epoch 152/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8467 - accuracy: 0.6369 - val_loss: 0.8577 - val_accuracy: 0.6267\n",
            "Epoch 153/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8492 - accuracy: 0.6367 - val_loss: 0.8806 - val_accuracy: 0.6292\n",
            "Epoch 154/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8647 - accuracy: 0.6308 - val_loss: 0.8843 - val_accuracy: 0.6242\n",
            "Epoch 155/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8711 - accuracy: 0.6239 - val_loss: 0.8572 - val_accuracy: 0.6392\n",
            "Epoch 156/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8611 - accuracy: 0.6283 - val_loss: 0.8391 - val_accuracy: 0.6333\n",
            "Epoch 157/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6447 - val_loss: 0.8377 - val_accuracy: 0.6483\n",
            "Epoch 158/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8495 - accuracy: 0.6275 - val_loss: 0.8568 - val_accuracy: 0.6325\n",
            "Epoch 159/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8416 - accuracy: 0.6389 - val_loss: 0.8524 - val_accuracy: 0.6308\n",
            "Epoch 160/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8429 - accuracy: 0.6386 - val_loss: 0.8396 - val_accuracy: 0.6442\n",
            "Epoch 161/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8320 - accuracy: 0.6408 - val_loss: 0.8545 - val_accuracy: 0.6367\n",
            "Epoch 162/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8402 - accuracy: 0.6358 - val_loss: 0.8756 - val_accuracy: 0.6258\n",
            "Epoch 163/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8540 - accuracy: 0.6308 - val_loss: 0.8296 - val_accuracy: 0.6500\n",
            "Epoch 164/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8374 - accuracy: 0.6381 - val_loss: 0.8593 - val_accuracy: 0.6433\n",
            "Epoch 165/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8597 - accuracy: 0.6211 - val_loss: 0.8543 - val_accuracy: 0.6342\n",
            "Epoch 166/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8259 - accuracy: 0.6367 - val_loss: 0.8767 - val_accuracy: 0.6275\n",
            "Epoch 167/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8387 - accuracy: 0.6414 - val_loss: 0.8637 - val_accuracy: 0.6183\n",
            "Epoch 168/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8370 - accuracy: 0.6372 - val_loss: 0.8535 - val_accuracy: 0.6250\n",
            "Epoch 169/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8497 - accuracy: 0.6381 - val_loss: 0.8605 - val_accuracy: 0.6308\n",
            "Epoch 170/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8534 - accuracy: 0.6308 - val_loss: 0.8743 - val_accuracy: 0.6175\n",
            "Epoch 171/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.6350 - val_loss: 0.8539 - val_accuracy: 0.6425\n",
            "Epoch 172/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8305 - accuracy: 0.6400 - val_loss: 0.8350 - val_accuracy: 0.6575\n",
            "Epoch 173/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.6347 - val_loss: 0.8668 - val_accuracy: 0.6242\n",
            "Epoch 174/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8375 - accuracy: 0.6314 - val_loss: 0.8458 - val_accuracy: 0.6275\n",
            "Epoch 175/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8405 - accuracy: 0.6414 - val_loss: 0.8394 - val_accuracy: 0.6333\n",
            "Epoch 176/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8300 - accuracy: 0.6406 - val_loss: 0.8284 - val_accuracy: 0.6367\n",
            "Epoch 177/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8342 - accuracy: 0.6353 - val_loss: 0.8357 - val_accuracy: 0.6500\n",
            "Epoch 178/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8379 - accuracy: 0.6392 - val_loss: 0.8284 - val_accuracy: 0.6358\n",
            "Epoch 179/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8409 - accuracy: 0.6361 - val_loss: 0.8234 - val_accuracy: 0.6550\n",
            "Epoch 180/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8317 - accuracy: 0.6356 - val_loss: 0.9567 - val_accuracy: 0.6158\n",
            "Epoch 181/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.6431 - val_loss: 0.9189 - val_accuracy: 0.5892\n",
            "Epoch 182/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8413 - accuracy: 0.6414 - val_loss: 0.8304 - val_accuracy: 0.6400\n",
            "Epoch 183/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8377 - accuracy: 0.6314 - val_loss: 0.8314 - val_accuracy: 0.6375\n",
            "Epoch 184/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8191 - accuracy: 0.6467 - val_loss: 0.8680 - val_accuracy: 0.6183\n",
            "Epoch 185/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8493 - accuracy: 0.6269 - val_loss: 0.8355 - val_accuracy: 0.6508\n",
            "Epoch 186/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8344 - accuracy: 0.6375 - val_loss: 0.8071 - val_accuracy: 0.6600\n",
            "Epoch 187/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8294 - accuracy: 0.6353 - val_loss: 0.8649 - val_accuracy: 0.6425\n",
            "Epoch 188/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8290 - accuracy: 0.6411 - val_loss: 0.8448 - val_accuracy: 0.6350\n",
            "Epoch 189/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8518 - accuracy: 0.6256 - val_loss: 0.8404 - val_accuracy: 0.6450\n",
            "Epoch 190/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8249 - accuracy: 0.6481 - val_loss: 0.8460 - val_accuracy: 0.6400\n",
            "Epoch 191/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8458 - accuracy: 0.6303 - val_loss: 0.8498 - val_accuracy: 0.6400\n",
            "Epoch 192/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.6500 - val_loss: 0.8286 - val_accuracy: 0.6383\n",
            "Epoch 193/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8197 - accuracy: 0.6461 - val_loss: 0.8386 - val_accuracy: 0.6317\n",
            "Epoch 194/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.6356 - val_loss: 0.8782 - val_accuracy: 0.6358\n",
            "Epoch 195/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8253 - accuracy: 0.6353 - val_loss: 0.8543 - val_accuracy: 0.6367\n",
            "Epoch 196/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8228 - accuracy: 0.6397 - val_loss: 0.8592 - val_accuracy: 0.6217\n",
            "Epoch 197/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8390 - accuracy: 0.6339 - val_loss: 0.8379 - val_accuracy: 0.6500\n",
            "Epoch 198/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8340 - accuracy: 0.6417 - val_loss: 0.8273 - val_accuracy: 0.6525\n",
            "Epoch 199/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8363 - accuracy: 0.6317 - val_loss: 0.8466 - val_accuracy: 0.6408\n",
            "Epoch 200/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8209 - accuracy: 0.6436 - val_loss: 0.8130 - val_accuracy: 0.6533\n",
            "Epoch 201/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8259 - accuracy: 0.6369 - val_loss: 0.8127 - val_accuracy: 0.6600\n",
            "Epoch 202/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8229 - accuracy: 0.6461 - val_loss: 0.8689 - val_accuracy: 0.6283\n",
            "Epoch 203/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.6425 - val_loss: 0.8751 - val_accuracy: 0.6367\n",
            "Epoch 204/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8246 - accuracy: 0.6364 - val_loss: 0.8167 - val_accuracy: 0.6592\n",
            "Epoch 205/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8501 - accuracy: 0.6308 - val_loss: 0.8274 - val_accuracy: 0.6258\n",
            "Epoch 206/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8237 - accuracy: 0.6431 - val_loss: 0.8319 - val_accuracy: 0.6300\n",
            "Epoch 207/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8304 - accuracy: 0.6361 - val_loss: 0.8182 - val_accuracy: 0.6517\n",
            "Epoch 208/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8339 - accuracy: 0.6397 - val_loss: 0.8349 - val_accuracy: 0.6392\n",
            "Epoch 209/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8479 - accuracy: 0.6356 - val_loss: 0.8485 - val_accuracy: 0.6317\n",
            "Epoch 210/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.6342 - val_loss: 0.8039 - val_accuracy: 0.6667\n",
            "Epoch 211/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8272 - accuracy: 0.6406 - val_loss: 0.8142 - val_accuracy: 0.6492\n",
            "Epoch 212/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8313 - accuracy: 0.6428 - val_loss: 0.8812 - val_accuracy: 0.6258\n",
            "Epoch 213/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8137 - accuracy: 0.6408 - val_loss: 0.8203 - val_accuracy: 0.6458\n",
            "Epoch 214/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8278 - accuracy: 0.6414 - val_loss: 0.8210 - val_accuracy: 0.6575\n",
            "Epoch 215/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8200 - accuracy: 0.6414 - val_loss: 0.8171 - val_accuracy: 0.6433\n",
            "Epoch 216/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8259 - accuracy: 0.6389 - val_loss: 0.8165 - val_accuracy: 0.6550\n",
            "Epoch 217/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8176 - accuracy: 0.6533 - val_loss: 0.8069 - val_accuracy: 0.6558\n",
            "Epoch 218/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8335 - accuracy: 0.6411 - val_loss: 0.8588 - val_accuracy: 0.6250\n",
            "Epoch 219/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8274 - accuracy: 0.6453 - val_loss: 0.8188 - val_accuracy: 0.6483\n",
            "Epoch 220/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8265 - accuracy: 0.6394 - val_loss: 0.8389 - val_accuracy: 0.6442\n",
            "Epoch 221/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8178 - accuracy: 0.6444 - val_loss: 0.8228 - val_accuracy: 0.6342\n",
            "Epoch 222/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8307 - accuracy: 0.6397 - val_loss: 0.8411 - val_accuracy: 0.6492\n",
            "Epoch 223/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8138 - accuracy: 0.6522 - val_loss: 0.8173 - val_accuracy: 0.6417\n",
            "Epoch 224/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8430 - accuracy: 0.6353 - val_loss: 0.8593 - val_accuracy: 0.6408\n",
            "Epoch 225/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.6403 - val_loss: 0.8466 - val_accuracy: 0.6400\n",
            "Epoch 226/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8340 - accuracy: 0.6311 - val_loss: 0.8271 - val_accuracy: 0.6467\n",
            "Epoch 227/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8207 - accuracy: 0.6422 - val_loss: 0.8387 - val_accuracy: 0.6517\n",
            "Epoch 228/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8260 - accuracy: 0.6394 - val_loss: 0.8268 - val_accuracy: 0.6383\n",
            "Epoch 229/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.6386 - val_loss: 0.8615 - val_accuracy: 0.6425\n",
            "Epoch 230/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8295 - accuracy: 0.6339 - val_loss: 0.8122 - val_accuracy: 0.6667\n",
            "Epoch 231/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8086 - accuracy: 0.6483 - val_loss: 0.8457 - val_accuracy: 0.6217\n",
            "Epoch 232/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8099 - accuracy: 0.6536 - val_loss: 0.8276 - val_accuracy: 0.6542\n",
            "Epoch 233/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8198 - accuracy: 0.6425 - val_loss: 0.8129 - val_accuracy: 0.6617\n",
            "Epoch 234/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8346 - accuracy: 0.6297 - val_loss: 0.8417 - val_accuracy: 0.6458\n",
            "Epoch 235/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8070 - accuracy: 0.6478 - val_loss: 0.8175 - val_accuracy: 0.6483\n",
            "Epoch 236/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.6369 - val_loss: 0.8894 - val_accuracy: 0.6208\n",
            "Epoch 237/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8353 - accuracy: 0.6339 - val_loss: 0.8255 - val_accuracy: 0.6417\n",
            "Epoch 238/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8167 - accuracy: 0.6442 - val_loss: 0.8696 - val_accuracy: 0.6333\n",
            "Epoch 239/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8229 - accuracy: 0.6358 - val_loss: 0.8125 - val_accuracy: 0.6450\n",
            "Epoch 240/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.6406 - val_loss: 0.8555 - val_accuracy: 0.6242\n",
            "Epoch 241/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8336 - accuracy: 0.6364 - val_loss: 0.8222 - val_accuracy: 0.6442\n",
            "Epoch 242/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8215 - accuracy: 0.6394 - val_loss: 0.8189 - val_accuracy: 0.6475\n",
            "Epoch 243/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8275 - accuracy: 0.6342 - val_loss: 0.8398 - val_accuracy: 0.6467\n",
            "Epoch 244/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8150 - accuracy: 0.6444 - val_loss: 0.8411 - val_accuracy: 0.6375\n",
            "Epoch 245/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8123 - accuracy: 0.6511 - val_loss: 0.8405 - val_accuracy: 0.6442\n",
            "Epoch 246/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8109 - accuracy: 0.6450 - val_loss: 0.8105 - val_accuracy: 0.6542\n",
            "Epoch 247/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8121 - accuracy: 0.6514 - val_loss: 0.7937 - val_accuracy: 0.6567\n",
            "Epoch 248/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8024 - accuracy: 0.6514 - val_loss: 0.8203 - val_accuracy: 0.6583\n",
            "Epoch 249/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8223 - accuracy: 0.6475 - val_loss: 0.7947 - val_accuracy: 0.6625\n",
            "Epoch 250/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8480 - accuracy: 0.6328 - val_loss: 0.8294 - val_accuracy: 0.6492\n",
            "Epoch 251/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8097 - accuracy: 0.6431 - val_loss: 0.8099 - val_accuracy: 0.6658\n",
            "Epoch 252/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8298 - accuracy: 0.6386 - val_loss: 0.8447 - val_accuracy: 0.6183\n",
            "Epoch 253/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8249 - accuracy: 0.6433 - val_loss: 0.8079 - val_accuracy: 0.6500\n",
            "Epoch 254/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8128 - accuracy: 0.6400 - val_loss: 0.8337 - val_accuracy: 0.6508\n",
            "Epoch 255/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8151 - accuracy: 0.6522 - val_loss: 0.8434 - val_accuracy: 0.6367\n",
            "Epoch 256/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.6453 - val_loss: 0.8581 - val_accuracy: 0.6267\n",
            "Epoch 257/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.6406 - val_loss: 0.8118 - val_accuracy: 0.6592\n",
            "Epoch 258/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8194 - accuracy: 0.6431 - val_loss: 0.8189 - val_accuracy: 0.6433\n",
            "Epoch 259/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8212 - accuracy: 0.6372 - val_loss: 0.8282 - val_accuracy: 0.6408\n",
            "Epoch 260/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8470 - accuracy: 0.6339 - val_loss: 0.8296 - val_accuracy: 0.6317\n",
            "Epoch 261/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8366 - accuracy: 0.6431 - val_loss: 0.8313 - val_accuracy: 0.6433\n",
            "Epoch 262/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8245 - accuracy: 0.6419 - val_loss: 0.8032 - val_accuracy: 0.6600\n",
            "Epoch 263/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8248 - accuracy: 0.6431 - val_loss: 0.8270 - val_accuracy: 0.6450\n",
            "Epoch 264/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8041 - accuracy: 0.6494 - val_loss: 0.8372 - val_accuracy: 0.6308\n",
            "Epoch 265/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8181 - accuracy: 0.6458 - val_loss: 0.8483 - val_accuracy: 0.6408\n",
            "Epoch 266/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8021 - accuracy: 0.6539 - val_loss: 0.7937 - val_accuracy: 0.6600\n",
            "Epoch 267/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.6522 - val_loss: 0.8214 - val_accuracy: 0.6442\n",
            "Epoch 268/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8083 - accuracy: 0.6503 - val_loss: 0.8385 - val_accuracy: 0.6475\n",
            "Epoch 269/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8087 - accuracy: 0.6442 - val_loss: 0.8266 - val_accuracy: 0.6433\n",
            "Epoch 270/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8285 - accuracy: 0.6375 - val_loss: 0.8014 - val_accuracy: 0.6592\n",
            "Epoch 271/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8108 - accuracy: 0.6397 - val_loss: 0.8318 - val_accuracy: 0.6475\n",
            "Epoch 272/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8262 - accuracy: 0.6378 - val_loss: 0.8308 - val_accuracy: 0.6442\n",
            "Epoch 273/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8127 - accuracy: 0.6472 - val_loss: 0.7985 - val_accuracy: 0.6525\n",
            "Epoch 274/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8058 - accuracy: 0.6472 - val_loss: 0.8089 - val_accuracy: 0.6492\n",
            "Epoch 275/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8411 - accuracy: 0.6297 - val_loss: 0.8247 - val_accuracy: 0.6508\n",
            "Epoch 276/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8107 - accuracy: 0.6472 - val_loss: 0.8414 - val_accuracy: 0.6508\n",
            "Epoch 277/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8009 - accuracy: 0.6522 - val_loss: 0.8222 - val_accuracy: 0.6483\n",
            "Epoch 278/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8131 - accuracy: 0.6408 - val_loss: 0.9222 - val_accuracy: 0.6242\n",
            "Epoch 279/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8275 - accuracy: 0.6403 - val_loss: 0.7926 - val_accuracy: 0.6583\n",
            "Epoch 280/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8037 - accuracy: 0.6533 - val_loss: 0.8224 - val_accuracy: 0.6458\n",
            "Epoch 281/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8001 - accuracy: 0.6556 - val_loss: 0.8596 - val_accuracy: 0.6325\n",
            "Epoch 282/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8211 - accuracy: 0.6389 - val_loss: 0.8093 - val_accuracy: 0.6558\n",
            "Epoch 283/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8048 - accuracy: 0.6508 - val_loss: 0.7965 - val_accuracy: 0.6608\n",
            "Epoch 284/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8047 - accuracy: 0.6453 - val_loss: 0.8361 - val_accuracy: 0.6467\n",
            "Epoch 285/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8391 - accuracy: 0.6314 - val_loss: 0.9516 - val_accuracy: 0.6100\n",
            "Epoch 286/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8343 - accuracy: 0.6325 - val_loss: 0.8048 - val_accuracy: 0.6592\n",
            "Epoch 287/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8042 - accuracy: 0.6525 - val_loss: 0.8049 - val_accuracy: 0.6392\n",
            "Epoch 288/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8110 - accuracy: 0.6458 - val_loss: 0.8101 - val_accuracy: 0.6683\n",
            "Epoch 289/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8086 - accuracy: 0.6500 - val_loss: 0.8436 - val_accuracy: 0.6292\n",
            "Epoch 290/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8171 - accuracy: 0.6417 - val_loss: 0.8052 - val_accuracy: 0.6600\n",
            "Epoch 291/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7995 - accuracy: 0.6547 - val_loss: 0.8334 - val_accuracy: 0.6450\n",
            "Epoch 292/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8032 - accuracy: 0.6547 - val_loss: 0.8016 - val_accuracy: 0.6608\n",
            "Epoch 293/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8157 - accuracy: 0.6453 - val_loss: 0.8207 - val_accuracy: 0.6450\n",
            "Epoch 294/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.6494 - val_loss: 0.8666 - val_accuracy: 0.6300\n",
            "Epoch 295/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8019 - accuracy: 0.6431 - val_loss: 0.8746 - val_accuracy: 0.6183\n",
            "Epoch 296/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8016 - accuracy: 0.6597 - val_loss: 0.8505 - val_accuracy: 0.6400\n",
            "Epoch 297/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8055 - accuracy: 0.6494 - val_loss: 0.8243 - val_accuracy: 0.6542\n",
            "Epoch 298/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8075 - accuracy: 0.6481 - val_loss: 0.9614 - val_accuracy: 0.5967\n",
            "Epoch 299/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8124 - accuracy: 0.6503 - val_loss: 0.8291 - val_accuracy: 0.6467\n",
            "Epoch 300/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7962 - accuracy: 0.6536 - val_loss: 0.8202 - val_accuracy: 0.6558\n",
            "Epoch 301/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.6614 - val_loss: 0.8158 - val_accuracy: 0.6483\n",
            "Epoch 302/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.6447 - val_loss: 0.8017 - val_accuracy: 0.6525\n",
            "Epoch 303/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8006 - accuracy: 0.6594 - val_loss: 0.8507 - val_accuracy: 0.6342\n",
            "Epoch 304/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8239 - accuracy: 0.6467 - val_loss: 0.7979 - val_accuracy: 0.6692\n",
            "Epoch 305/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.6531 - val_loss: 0.8160 - val_accuracy: 0.6475\n",
            "Epoch 306/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8045 - accuracy: 0.6508 - val_loss: 0.8215 - val_accuracy: 0.6450\n",
            "Epoch 307/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.6567 - val_loss: 0.8031 - val_accuracy: 0.6567\n",
            "Epoch 308/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8106 - accuracy: 0.6550 - val_loss: 0.8439 - val_accuracy: 0.6433\n",
            "Epoch 309/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8025 - accuracy: 0.6542 - val_loss: 0.8439 - val_accuracy: 0.6525\n",
            "Epoch 310/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8363 - accuracy: 0.6375 - val_loss: 0.8099 - val_accuracy: 0.6583\n",
            "Epoch 311/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7939 - accuracy: 0.6508 - val_loss: 0.8225 - val_accuracy: 0.6533\n",
            "Epoch 312/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8018 - accuracy: 0.6533 - val_loss: 0.8219 - val_accuracy: 0.6525\n",
            "Epoch 313/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8094 - accuracy: 0.6497 - val_loss: 0.8015 - val_accuracy: 0.6583\n",
            "Epoch 314/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7939 - accuracy: 0.6561 - val_loss: 0.8148 - val_accuracy: 0.6500\n",
            "Epoch 315/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8316 - accuracy: 0.6417 - val_loss: 0.8360 - val_accuracy: 0.6400\n",
            "Epoch 316/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8310 - accuracy: 0.6411 - val_loss: 0.8286 - val_accuracy: 0.6558\n",
            "Epoch 317/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.6550 - val_loss: 0.8092 - val_accuracy: 0.6533\n",
            "Epoch 318/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8068 - accuracy: 0.6556 - val_loss: 0.8846 - val_accuracy: 0.6175\n",
            "Epoch 319/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.6475 - val_loss: 0.7986 - val_accuracy: 0.6558\n",
            "Epoch 320/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7920 - accuracy: 0.6519 - val_loss: 0.8003 - val_accuracy: 0.6550\n",
            "Epoch 321/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7968 - accuracy: 0.6547 - val_loss: 0.7972 - val_accuracy: 0.6533\n",
            "Epoch 322/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7908 - accuracy: 0.6522 - val_loss: 0.8817 - val_accuracy: 0.6308\n",
            "Epoch 323/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8407 - accuracy: 0.6364 - val_loss: 0.8433 - val_accuracy: 0.6383\n",
            "Epoch 324/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.6422 - val_loss: 0.8400 - val_accuracy: 0.6350\n",
            "Epoch 325/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8114 - accuracy: 0.6414 - val_loss: 0.8103 - val_accuracy: 0.6483\n",
            "Epoch 326/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.6564 - val_loss: 0.8400 - val_accuracy: 0.6308\n",
            "Epoch 327/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.6492 - val_loss: 0.8068 - val_accuracy: 0.6425\n",
            "Epoch 328/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7914 - accuracy: 0.6550 - val_loss: 0.8149 - val_accuracy: 0.6542\n",
            "Epoch 329/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.6475 - val_loss: 0.7898 - val_accuracy: 0.6617\n",
            "Epoch 330/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7987 - accuracy: 0.6586 - val_loss: 0.8285 - val_accuracy: 0.6592\n",
            "Epoch 331/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7974 - accuracy: 0.6494 - val_loss: 0.7928 - val_accuracy: 0.6625\n",
            "Epoch 332/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7867 - accuracy: 0.6625 - val_loss: 0.8039 - val_accuracy: 0.6525\n",
            "Epoch 333/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.6542 - val_loss: 0.8259 - val_accuracy: 0.6433\n",
            "Epoch 334/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7919 - accuracy: 0.6561 - val_loss: 0.8072 - val_accuracy: 0.6442\n",
            "Epoch 335/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7977 - accuracy: 0.6606 - val_loss: 0.8190 - val_accuracy: 0.6400\n",
            "Epoch 336/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8101 - accuracy: 0.6456 - val_loss: 0.8547 - val_accuracy: 0.6275\n",
            "Epoch 337/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8216 - accuracy: 0.6397 - val_loss: 0.8282 - val_accuracy: 0.6467\n",
            "Epoch 338/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7971 - accuracy: 0.6547 - val_loss: 0.8291 - val_accuracy: 0.6350\n",
            "Epoch 339/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8182 - accuracy: 0.6411 - val_loss: 0.8114 - val_accuracy: 0.6458\n",
            "Epoch 340/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7948 - accuracy: 0.6533 - val_loss: 0.8240 - val_accuracy: 0.6450\n",
            "Epoch 341/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7838 - accuracy: 0.6511 - val_loss: 0.7830 - val_accuracy: 0.6608\n",
            "Epoch 342/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8032 - accuracy: 0.6461 - val_loss: 0.8509 - val_accuracy: 0.6208\n",
            "Epoch 343/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8008 - accuracy: 0.6500 - val_loss: 0.7963 - val_accuracy: 0.6475\n",
            "Epoch 344/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8204 - accuracy: 0.6436 - val_loss: 0.8642 - val_accuracy: 0.6500\n",
            "Epoch 345/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8091 - accuracy: 0.6494 - val_loss: 0.8121 - val_accuracy: 0.6475\n",
            "Epoch 346/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8052 - accuracy: 0.6492 - val_loss: 0.8443 - val_accuracy: 0.6442\n",
            "Epoch 347/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8047 - accuracy: 0.6439 - val_loss: 0.8184 - val_accuracy: 0.6508\n",
            "Epoch 348/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7997 - accuracy: 0.6569 - val_loss: 0.8080 - val_accuracy: 0.6517\n",
            "Epoch 349/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7875 - accuracy: 0.6600 - val_loss: 0.7835 - val_accuracy: 0.6633\n",
            "Epoch 350/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8018 - accuracy: 0.6497 - val_loss: 0.8343 - val_accuracy: 0.6383\n",
            "Epoch 351/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7974 - accuracy: 0.6558 - val_loss: 0.7808 - val_accuracy: 0.6675\n",
            "Epoch 352/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7849 - accuracy: 0.6550 - val_loss: 0.7927 - val_accuracy: 0.6525\n",
            "Epoch 353/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8043 - accuracy: 0.6567 - val_loss: 0.8893 - val_accuracy: 0.6133\n",
            "Epoch 354/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7923 - accuracy: 0.6517 - val_loss: 0.8139 - val_accuracy: 0.6567\n",
            "Epoch 355/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7952 - accuracy: 0.6569 - val_loss: 0.8312 - val_accuracy: 0.6400\n",
            "Epoch 356/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7899 - accuracy: 0.6603 - val_loss: 0.8224 - val_accuracy: 0.6550\n",
            "Epoch 357/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.6508 - val_loss: 0.7954 - val_accuracy: 0.6650\n",
            "Epoch 358/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7999 - accuracy: 0.6542 - val_loss: 0.8076 - val_accuracy: 0.6483\n",
            "Epoch 359/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7930 - accuracy: 0.6497 - val_loss: 0.7856 - val_accuracy: 0.6667\n",
            "Epoch 360/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7798 - accuracy: 0.6636 - val_loss: 0.8063 - val_accuracy: 0.6508\n",
            "Epoch 361/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8164 - accuracy: 0.6453 - val_loss: 0.8573 - val_accuracy: 0.6300\n",
            "Epoch 362/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8052 - accuracy: 0.6478 - val_loss: 0.7848 - val_accuracy: 0.6567\n",
            "Epoch 363/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7862 - accuracy: 0.6517 - val_loss: 0.8369 - val_accuracy: 0.6433\n",
            "Epoch 364/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7828 - accuracy: 0.6603 - val_loss: 0.8018 - val_accuracy: 0.6408\n",
            "Epoch 365/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7827 - accuracy: 0.6583 - val_loss: 0.8021 - val_accuracy: 0.6500\n",
            "Epoch 366/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7956 - accuracy: 0.6536 - val_loss: 0.7980 - val_accuracy: 0.6642\n",
            "Epoch 367/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7979 - accuracy: 0.6522 - val_loss: 0.8258 - val_accuracy: 0.6400\n",
            "Epoch 368/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7995 - accuracy: 0.6525 - val_loss: 0.7989 - val_accuracy: 0.6550\n",
            "Epoch 369/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8011 - accuracy: 0.6486 - val_loss: 0.8484 - val_accuracy: 0.6408\n",
            "Epoch 370/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7820 - accuracy: 0.6586 - val_loss: 0.7951 - val_accuracy: 0.6508\n",
            "Epoch 371/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.6583 - val_loss: 0.8089 - val_accuracy: 0.6375\n",
            "Epoch 372/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7784 - accuracy: 0.6608 - val_loss: 0.8617 - val_accuracy: 0.6358\n",
            "Epoch 373/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7850 - accuracy: 0.6658 - val_loss: 0.8190 - val_accuracy: 0.6442\n",
            "Epoch 374/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.6558 - val_loss: 0.8055 - val_accuracy: 0.6483\n",
            "Epoch 375/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7865 - accuracy: 0.6556 - val_loss: 0.7835 - val_accuracy: 0.6550\n",
            "Epoch 376/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.6572 - val_loss: 0.8223 - val_accuracy: 0.6475\n",
            "Epoch 377/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7987 - accuracy: 0.6431 - val_loss: 0.8395 - val_accuracy: 0.6358\n",
            "Epoch 378/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.6628 - val_loss: 0.8047 - val_accuracy: 0.6517\n",
            "Epoch 379/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7897 - accuracy: 0.6606 - val_loss: 0.7839 - val_accuracy: 0.6467\n",
            "Epoch 380/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7825 - accuracy: 0.6653 - val_loss: 0.8141 - val_accuracy: 0.6458\n",
            "Epoch 381/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.6636 - val_loss: 0.7909 - val_accuracy: 0.6525\n",
            "Epoch 382/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8358 - accuracy: 0.6425 - val_loss: 0.8299 - val_accuracy: 0.6467\n",
            "Epoch 383/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7870 - accuracy: 0.6525 - val_loss: 0.7989 - val_accuracy: 0.6508\n",
            "Epoch 384/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7798 - accuracy: 0.6658 - val_loss: 0.8024 - val_accuracy: 0.6450\n",
            "Epoch 385/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.6569 - val_loss: 0.8124 - val_accuracy: 0.6408\n",
            "Epoch 386/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8026 - accuracy: 0.6514 - val_loss: 0.7989 - val_accuracy: 0.6617\n",
            "Epoch 387/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.6506 - val_loss: 0.8488 - val_accuracy: 0.6300\n",
            "Epoch 388/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.6533 - val_loss: 0.7949 - val_accuracy: 0.6650\n",
            "Epoch 389/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7763 - accuracy: 0.6600 - val_loss: 0.8336 - val_accuracy: 0.6425\n",
            "Epoch 390/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8108 - accuracy: 0.6386 - val_loss: 0.8008 - val_accuracy: 0.6433\n",
            "Epoch 391/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7860 - accuracy: 0.6597 - val_loss: 0.8090 - val_accuracy: 0.6483\n",
            "Epoch 392/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7994 - accuracy: 0.6489 - val_loss: 0.7938 - val_accuracy: 0.6567\n",
            "Epoch 393/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6594 - val_loss: 0.7783 - val_accuracy: 0.6658\n",
            "Epoch 394/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.6508 - val_loss: 0.8236 - val_accuracy: 0.6442\n",
            "Epoch 395/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7810 - accuracy: 0.6567 - val_loss: 0.8121 - val_accuracy: 0.6467\n",
            "Epoch 396/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7868 - accuracy: 0.6525 - val_loss: 0.8128 - val_accuracy: 0.6525\n",
            "Epoch 397/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7885 - accuracy: 0.6531 - val_loss: 0.8180 - val_accuracy: 0.6467\n",
            "Epoch 398/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7876 - accuracy: 0.6528 - val_loss: 0.8894 - val_accuracy: 0.6242\n",
            "Epoch 399/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7892 - accuracy: 0.6469 - val_loss: 0.7985 - val_accuracy: 0.6483\n",
            "Epoch 400/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7788 - accuracy: 0.6553 - val_loss: 0.7825 - val_accuracy: 0.6550\n",
            "Epoch 401/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.6539 - val_loss: 0.7847 - val_accuracy: 0.6600\n",
            "Epoch 402/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8077 - accuracy: 0.6503 - val_loss: 0.8219 - val_accuracy: 0.6467\n",
            "Epoch 403/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.6558 - val_loss: 0.8176 - val_accuracy: 0.6375\n",
            "Epoch 404/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.6603 - val_loss: 0.8022 - val_accuracy: 0.6500\n",
            "Epoch 405/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7780 - accuracy: 0.6597 - val_loss: 0.7985 - val_accuracy: 0.6508\n",
            "Epoch 406/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.6606 - val_loss: 0.7940 - val_accuracy: 0.6442\n",
            "Epoch 407/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.6608 - val_loss: 0.7967 - val_accuracy: 0.6358\n",
            "Epoch 408/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.6589 - val_loss: 0.7858 - val_accuracy: 0.6708\n",
            "Epoch 409/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7968 - accuracy: 0.6531 - val_loss: 0.8234 - val_accuracy: 0.6575\n",
            "Epoch 410/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7941 - accuracy: 0.6581 - val_loss: 0.8593 - val_accuracy: 0.6333\n",
            "Epoch 411/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7857 - accuracy: 0.6572 - val_loss: 0.7989 - val_accuracy: 0.6467\n",
            "Epoch 412/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.6522 - val_loss: 0.8657 - val_accuracy: 0.6325\n",
            "Epoch 413/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8240 - accuracy: 0.6381 - val_loss: 0.8003 - val_accuracy: 0.6458\n",
            "Epoch 414/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.6492 - val_loss: 0.8000 - val_accuracy: 0.6567\n",
            "Epoch 415/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8004 - accuracy: 0.6519 - val_loss: 0.7866 - val_accuracy: 0.6583\n",
            "Epoch 416/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.6628 - val_loss: 0.8128 - val_accuracy: 0.6608\n",
            "Epoch 417/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.6633 - val_loss: 0.7996 - val_accuracy: 0.6600\n",
            "Epoch 418/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7747 - accuracy: 0.6600 - val_loss: 0.7748 - val_accuracy: 0.6625\n",
            "Epoch 419/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.6672 - val_loss: 0.7975 - val_accuracy: 0.6550\n",
            "Epoch 420/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.6544 - val_loss: 0.8029 - val_accuracy: 0.6400\n",
            "Epoch 421/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7936 - accuracy: 0.6547 - val_loss: 0.7938 - val_accuracy: 0.6667\n",
            "Epoch 422/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7866 - accuracy: 0.6514 - val_loss: 0.8676 - val_accuracy: 0.6242\n",
            "Epoch 423/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7802 - accuracy: 0.6642 - val_loss: 0.8127 - val_accuracy: 0.6533\n",
            "Epoch 424/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.6603 - val_loss: 0.7902 - val_accuracy: 0.6550\n",
            "Epoch 425/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7776 - accuracy: 0.6569 - val_loss: 0.8012 - val_accuracy: 0.6583\n",
            "Epoch 426/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.6511 - val_loss: 0.8431 - val_accuracy: 0.6183\n",
            "Epoch 427/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7686 - accuracy: 0.6608 - val_loss: 0.7863 - val_accuracy: 0.6483\n",
            "Epoch 428/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7906 - accuracy: 0.6558 - val_loss: 0.7880 - val_accuracy: 0.6525\n",
            "Epoch 429/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.6631 - val_loss: 0.7791 - val_accuracy: 0.6567\n",
            "Epoch 430/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7780 - accuracy: 0.6597 - val_loss: 0.7900 - val_accuracy: 0.6433\n",
            "Epoch 431/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.6636 - val_loss: 0.8230 - val_accuracy: 0.6458\n",
            "Epoch 432/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7787 - accuracy: 0.6572 - val_loss: 0.8036 - val_accuracy: 0.6475\n",
            "Epoch 433/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7954 - accuracy: 0.6539 - val_loss: 0.8293 - val_accuracy: 0.6483\n",
            "Epoch 434/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7757 - accuracy: 0.6628 - val_loss: 0.8231 - val_accuracy: 0.6358\n",
            "Epoch 435/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.6622 - val_loss: 0.7724 - val_accuracy: 0.6567\n",
            "Epoch 436/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7750 - accuracy: 0.6692 - val_loss: 0.7862 - val_accuracy: 0.6575\n",
            "Epoch 437/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7811 - accuracy: 0.6606 - val_loss: 0.8221 - val_accuracy: 0.6308\n",
            "Epoch 438/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7982 - accuracy: 0.6483 - val_loss: 0.8213 - val_accuracy: 0.6408\n",
            "Epoch 439/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7875 - accuracy: 0.6542 - val_loss: 0.7893 - val_accuracy: 0.6483\n",
            "Epoch 440/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7900 - accuracy: 0.6547 - val_loss: 0.7897 - val_accuracy: 0.6575\n",
            "Epoch 441/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.6614 - val_loss: 0.7824 - val_accuracy: 0.6692\n",
            "Epoch 442/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7820 - accuracy: 0.6569 - val_loss: 0.9832 - val_accuracy: 0.6033\n",
            "Epoch 443/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.6539 - val_loss: 0.8008 - val_accuracy: 0.6508\n",
            "Epoch 444/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7783 - accuracy: 0.6539 - val_loss: 0.7812 - val_accuracy: 0.6542\n",
            "Epoch 445/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7715 - accuracy: 0.6578 - val_loss: 0.8102 - val_accuracy: 0.6400\n",
            "Epoch 446/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.6636 - val_loss: 0.8026 - val_accuracy: 0.6442\n",
            "Epoch 447/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.6614 - val_loss: 0.7822 - val_accuracy: 0.6558\n",
            "Epoch 448/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7596 - accuracy: 0.6750 - val_loss: 0.7797 - val_accuracy: 0.6583\n",
            "Epoch 449/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 0.7706 - accuracy: 0.6539 - val_loss: 0.8205 - val_accuracy: 0.6375\n",
            "Epoch 450/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7738 - accuracy: 0.6608 - val_loss: 0.8127 - val_accuracy: 0.6625\n",
            "Epoch 451/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7644 - accuracy: 0.6586 - val_loss: 0.7964 - val_accuracy: 0.6558\n",
            "Epoch 452/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7834 - accuracy: 0.6519 - val_loss: 0.7772 - val_accuracy: 0.6625\n",
            "Epoch 453/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7769 - accuracy: 0.6558 - val_loss: 0.8508 - val_accuracy: 0.6250\n",
            "Epoch 454/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7675 - accuracy: 0.6631 - val_loss: 0.7890 - val_accuracy: 0.6517\n",
            "Epoch 455/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7727 - accuracy: 0.6517 - val_loss: 0.7813 - val_accuracy: 0.6633\n",
            "Epoch 456/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7886 - accuracy: 0.6631 - val_loss: 0.8616 - val_accuracy: 0.6392\n",
            "Epoch 457/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7763 - accuracy: 0.6553 - val_loss: 0.8044 - val_accuracy: 0.6500\n",
            "Epoch 458/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.6569 - val_loss: 0.7826 - val_accuracy: 0.6642\n",
            "Epoch 459/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.6531 - val_loss: 0.8204 - val_accuracy: 0.6600\n",
            "Epoch 460/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7685 - accuracy: 0.6639 - val_loss: 0.8422 - val_accuracy: 0.6300\n",
            "Epoch 461/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.6458 - val_loss: 0.7910 - val_accuracy: 0.6592\n",
            "Epoch 462/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7660 - accuracy: 0.6667 - val_loss: 0.8008 - val_accuracy: 0.6525\n",
            "Epoch 463/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.6600 - val_loss: 0.7860 - val_accuracy: 0.6642\n",
            "Epoch 464/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7982 - accuracy: 0.6503 - val_loss: 0.8116 - val_accuracy: 0.6542\n",
            "Epoch 465/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7745 - accuracy: 0.6589 - val_loss: 0.7827 - val_accuracy: 0.6558\n",
            "Epoch 466/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7628 - accuracy: 0.6586 - val_loss: 0.7787 - val_accuracy: 0.6517\n",
            "Epoch 467/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7708 - accuracy: 0.6644 - val_loss: 0.8092 - val_accuracy: 0.6600\n",
            "Epoch 468/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7782 - accuracy: 0.6511 - val_loss: 0.7802 - val_accuracy: 0.6667\n",
            "Epoch 469/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7632 - accuracy: 0.6636 - val_loss: 0.8198 - val_accuracy: 0.6617\n",
            "Epoch 470/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7719 - accuracy: 0.6600 - val_loss: 0.8451 - val_accuracy: 0.6267\n",
            "Epoch 471/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7759 - accuracy: 0.6572 - val_loss: 0.7840 - val_accuracy: 0.6567\n",
            "Epoch 472/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.6583 - val_loss: 0.7913 - val_accuracy: 0.6608\n",
            "Epoch 473/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.6617 - val_loss: 0.7852 - val_accuracy: 0.6542\n",
            "Epoch 474/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.6689 - val_loss: 0.7767 - val_accuracy: 0.6617\n",
            "Epoch 475/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.6631 - val_loss: 0.7871 - val_accuracy: 0.6517\n",
            "Epoch 476/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.6564 - val_loss: 0.8499 - val_accuracy: 0.6308\n",
            "Epoch 477/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.6642 - val_loss: 0.8180 - val_accuracy: 0.6475\n",
            "Epoch 478/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.6597 - val_loss: 0.7937 - val_accuracy: 0.6508\n",
            "Epoch 479/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7906 - accuracy: 0.6453 - val_loss: 0.7952 - val_accuracy: 0.6458\n",
            "Epoch 480/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7755 - accuracy: 0.6539 - val_loss: 0.7960 - val_accuracy: 0.6517\n",
            "Epoch 481/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7743 - accuracy: 0.6569 - val_loss: 0.8230 - val_accuracy: 0.6400\n",
            "Epoch 482/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8311 - accuracy: 0.6453 - val_loss: 0.8144 - val_accuracy: 0.6442\n",
            "Epoch 483/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7666 - accuracy: 0.6606 - val_loss: 0.7937 - val_accuracy: 0.6492\n",
            "Epoch 484/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.6614 - val_loss: 0.8053 - val_accuracy: 0.6408\n",
            "Epoch 485/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7762 - accuracy: 0.6597 - val_loss: 0.8345 - val_accuracy: 0.6392\n",
            "Epoch 486/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7752 - accuracy: 0.6689 - val_loss: 0.7965 - val_accuracy: 0.6417\n",
            "Epoch 487/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.6658 - val_loss: 0.7864 - val_accuracy: 0.6550\n",
            "Epoch 488/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7799 - accuracy: 0.6625 - val_loss: 0.7892 - val_accuracy: 0.6600\n",
            "Epoch 489/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7712 - accuracy: 0.6581 - val_loss: 0.8117 - val_accuracy: 0.6642\n",
            "Epoch 490/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.6686 - val_loss: 0.7738 - val_accuracy: 0.6625\n",
            "Epoch 491/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7635 - accuracy: 0.6639 - val_loss: 0.7730 - val_accuracy: 0.6567\n",
            "Epoch 492/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.6742 - val_loss: 0.8294 - val_accuracy: 0.6458\n",
            "Epoch 493/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.6592 - val_loss: 0.8024 - val_accuracy: 0.6450\n",
            "Epoch 494/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.6672 - val_loss: 0.8731 - val_accuracy: 0.6192\n",
            "Epoch 495/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7785 - accuracy: 0.6547 - val_loss: 0.7744 - val_accuracy: 0.6583\n",
            "Epoch 496/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.6703 - val_loss: 0.7768 - val_accuracy: 0.6642\n",
            "Epoch 497/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.6625 - val_loss: 0.8028 - val_accuracy: 0.6592\n",
            "Epoch 498/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7781 - accuracy: 0.6628 - val_loss: 0.8738 - val_accuracy: 0.6200\n",
            "Epoch 499/500\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7705 - accuracy: 0.6592 - val_loss: 0.7745 - val_accuracy: 0.6533\n",
            "Epoch 500/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7620 - accuracy: 0.6672 - val_loss: 0.7810 - val_accuracy: 0.6567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc      = history.history['accuracy']\n",
        "val_acc  = history.history['val_accuracy']\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  (epochs, acc)\n",
        "plt.plot  (epochs, val_acc)\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  (epochs, loss)\n",
        "plt.plot  (epochs, val_loss)\n",
        "plt.title ('Training and validation loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "Uqt8HA-CqFRx",
        "outputId": "2a57bf1d-8b5a-4639-992c-d90f34ae96b6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "rCEsefOLSku0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad2679b-6691-45cf-ec54-75a3d64e7d95"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7793241739273071\n",
            "Test accuracy: 0.6733333468437195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "-TMHOoQNS3QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34881886-65c9-459d-a09a-aef451603b6f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 6.0743104e-23, 6.9129074e-01, ..., 0.0000000e+00,\n",
              "        2.5410064e-13, 1.8383915e-07],\n",
              "       [0.0000000e+00, 1.0643613e-14, 7.7765805e-01, ..., 0.0000000e+00,\n",
              "        4.7149751e-07, 6.3850344e-03],\n",
              "       [1.7512974e-16, 9.5184312e-12, 1.2182840e-13, ..., 7.6187607e-16,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       ...,\n",
              "       [2.7535194e-01, 3.9030366e-02, 1.4739849e-12, ..., 2.5787473e-15,\n",
              "        3.0204967e-11, 3.2181650e-01],\n",
              "       [3.2687303e-01, 1.3509583e-01, 3.7219674e-19, ..., 2.0122684e-18,\n",
              "        1.1073566e-12, 4.9381983e-06],\n",
              "       [0.0000000e+00, 8.1513920e-29, 4.6277791e-01, ..., 0.0000000e+00,\n",
              "        4.1345345e-14, 1.3329309e-11]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual = np.argmax(y_test,axis=1)\n",
        "predicted = np.argsort(y_pred,axis=1)\n",
        "print(f\"Actual: {encoder.inverse_transform(actual[:5])}\\nPredicted: \")\n",
        "for i in predicted[:5,7:]:\n",
        "  print(encoder.inverse_transform(i))"
      ],
      "metadata": {
        "id": "LTKo0gpfTFfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a35399a-b70f-40fb-ca44-96cb5cc34147"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: ['Kubis' 'Kubis' 'Lidah Mertua' 'Mawar' 'Terung']\n",
            "Predicted: \n",
            "['Melati' 'Tomat' 'Kuping Gajah' 'Lavender' 'Kubis']\n",
            "['Melati' 'Kuping Gajah' 'Tomat' 'Lavender' 'Kubis']\n",
            "['Kangkung' 'Mawar' 'Melati' 'Lidah Mertua' 'Lidah Buaya']\n",
            "['Melati' 'Kuping Gajah' 'Kangkung' 'Tomat' 'Bayam Hijau']\n",
            "['Tomat' 'Melati' 'Kangkung' 'Lavender' 'Terung']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = model.predict([[temp, 1, 1, humidity]])\n",
        "output = np.argsort(input, axis=1)[:,7:].flatten()\n",
        "print(encoder.inverse_transform(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX6i9CvMiedh",
        "outputId": "948068c1-b37e-4c09-df81-511364add875"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tomat' 'Kangkung' 'Melati' 'Lavender' 'Terung']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation | LightGBM"
      ],
      "metadata": {
        "id": "F-N-y_41gBQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_2vVKRV2gQcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,4].values"
      ],
      "metadata": {
        "id": "NKSjWDUUgWDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# set aside 20% of train and test data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 8)"
      ],
      "metadata": {
        "id": "0YtGH5CkgnNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a lightgbm model\n",
        "import lightgbm as lgb\n",
        "\n",
        "model = lgb.LGBMClassifier()\n",
        "\n",
        "# Training the model using Training Data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqKUa4dUguSG",
        "outputId": "19c41371-f5ca-41a9-bc97-ac39d67c197f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the outputs over testing data\n",
        "y_pred=model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "hD5bZ3hegu32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Library to measure accuracy of model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Find accuracy on Expected Output and Predicted Output on Testing Data\n",
        "accuracy=accuracy_score(y_pred, y_test)\n",
        "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJSGdISMgxnp",
        "outputId": "0c2c2308-980e-4e7a-f3d0-b1e996012e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Model accuracy score: 0.6771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find Training Score on Expected Output and Predicted Output on Training Data\n",
        "y_pred_train = model.predict(X_train)\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8enDKW0hB4H",
        "outputId": "0b5a4011-3ae6-4807-e824-20982a16a045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training-set accuracy score: 0.9615\n"
          ]
        }
      ]
    }
  ]
}